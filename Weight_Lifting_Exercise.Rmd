# Weight Lifting Exercise

## Summary

This project is to build a machine learning algorithm to recognise different activity quality by using the measurements recorded by the sensors.  
We use the data set here:  
training data (https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)  
test data (https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)    
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har.  
We devided pml-training.csv into two parts, one for training and the other for cross validation. We removed variables that are not sensor measures and that consist mostly of NAs and blank. So 52 variables are used as predictors. The "classe" variable is the outcome variable. Both trees and random forests model are built. We adopt the random forests model which has higher accuracy on the cross validation data set. At last we used the random forests model to predict 20 different test cases in the testing set.

```{r setoptions, echo=FALSE}
opts_chunk$set(cache=TRUE,eval=TRUE)
```

## Data Process and Results
1.We read the original training data file, clean the data and split into a trainging set and a cross validation set.
```{r}
#read the orignal training data file
data<-read.csv("pml-training.csv",na.strings=c("NA",""))
#remove columns that consist mostly of NAs and blanks
newdata<-data[,colSums(!is.na(data)) == nrow(data)]
#remove columns X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,new_window,num_window, which are not sensor measurement 
#therefore leaves 53 columns (52 predictors and 1 outcome)
newdata <- subset(newdata,select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,new_window,num_window) )
#split the data set into training set and cross validation set
library(caret)
inTrain <- createDataPartition(y=newdata$classe,p=0.7, list=FALSE)
training <- newdata[inTrain,]   #13737 obs.
validation <- newdata[-inTrain,]    #5885 obs.   
```
2.We build the model and use the validation data set to calculate the out of sample error.
```{r}
#predicting with trees
Tree_Fit <- train(classe ~.,data = training,method="rpart")
#calculate out of sample error
confusionMatrix(validation$classe, predict(Tree_Fit, validation))
```
Trees model has 49.1% out of sample accuracy, or 50.9% out of sample error.

```{r}
#predicing with random forests
RF_Fit <- train(classe~.,data =training,method='rf')
#calculate out of sample error
confusionMatrix(validation$classe, predict(RF_Fit, validation))
```
Random forests model has 99.4% out of sample accuracy, or 0.6% out of sample error.

3.Random forests appear to have higher out of sample accuracy than trees. We apply random forest to the testing set.
```{r }
#read the testing set
testing<-read.csv("pml-testing.csv",na.strings=c("NA",""))
#preprocess the testing set
testProc<-subset(testing,select=names(newdata[,-53]))
#predict the class
answers<-predict(RF_Fit, testProc)
```
4.Generate the submission file.
```{r submit,eval=FALSE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(answers)
```